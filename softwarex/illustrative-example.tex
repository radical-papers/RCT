% {\em Provide at least one illustrative example to demonstrate the major
% functions.

% Optional: you may include one explanatory video that will appear next to
% your article, in the right hand side panel. (Please upload any video as a
% single supplementary file with your article. Only one MP4 formatted, with
% 50MB maximum size, video is possible per article. Recommended video
% dimensions are 640 x 480 at a maximum of 30 frames/second. Prior to
% submission please test and validate your .mp4 file at $
% http://elsevier-apps.sciverse.com/GadgetVideoPodcastPlayerWeb/verification$.
% This tool will display your video exactly in the same way as it will appear
% on ScienceDirect.).}

% \mtnote{Use a use case that requires a bag of heterogeneous tasks. Show how
% this example can become one state of a workflow and how this workflow is
% supported by EnTK\@. REPEX, EXTASY candidate examples.}

Multiple scientific domains can benefit from executing many-task applications
at scale~\cite{raicu2008many,iosup2011performance}. Independent of the domain
for which these applications are developed, their execution requires to run a
single task, a bag of tasks, or a workflow. In this context, tasks refers to
programs like, for example, GROMACS, NAMD, AMBER, AthenaMP, SPECFEM and many
others. Many-task applications requires to concurrently run multiple
instances of programs, using scale to reduce the total time to completion of
the whole execution.

As seen in Sec.~\ref{sec:description}, RCT support the execution of a single
task, a bag of tasks, and workflows expressed as a set or a sequence of
pipelines with stages and tasks. Because of the separation between manging
the concurrent and consecutive execution of tasks, and the computation
performance by each task, RCT support many-task application independent from
the scientific domain in which they are used. From RCT point of view, every
execution reduces exclusively to manging the execution of single or multiple
sets of programs in the form of black boxes.

RP executes set of tasks. The degree of concurrency of the execution depends
on the amount of available resources. Consider for example
Ref.~\cite{balasubramanian2016extasy}'s many-task application for the
simulation of molecular dynamics with an ensemble of 128 GROMACS simulations,
each requiring 24 CPU cores. The user can use RP API to describe a pilot job
with 3072 cores (Lis.~\ref{code:pilot}), 128 CUs (Lis.~\ref{code:units}) and
two managers to coordinate the acquisition of the pilot resources via RS on
an HPC machine and the concurrent execution of the 128 tasks on those
resources (Lis.~\ref{code:mgrs}).

% Fig.~\ref{fig:archs}a's numbers illustrate the resource acquisition and
% task execution process. PilotManager queues the pilot description on one of
% the available Launcher in RP client (Fig.~\ref{fig:archs}a.1). That
% Launcher uses RS to schedule the pilot as a job on the target resource via
% the resource's batch System (Fig.~\ref{fig:archs}a.2). The pilot job waits
% in the resource management system queue and, once scheduled, bootstraps the
% pilot's AgentMnager and Updater. AgentManager forks the StagerInput,
% Scheduler, Executor and StagerOutput components and the Updater notifies RP
% Client's Notifier that RP Agent is ready to execute tasks
% (Fig.~\ref{fig:archs}a.3).

% Upon notification, UnitManager queues all the available tasks onto Client's
% Scheduler that, in turns, queues those tasks into the StagerInput,
% depending on the chosen scheduling algorithm (Fig.~\ref{fig:archs}a.4). If
% required, StagerInput stages the tasks' input files to the target resource
% and then tasks are queued to the Updater and passed to the chosen RP
% Agent's AgentManager (Fig.~\ref{fig:archs}a.5). At that point, tasks are
% passed to a StagerInput where input files are linked and made available to
% each task, and then queued to the RP Agent's Scheduler
% (Fig.~\ref{fig:archs}a.6). Scheduler places tasks on suitable partitions of
% the pilot's resources and then queues tasks to the Executor so that, when
% those partitions of resource becomes available, tasks are executed
% (Fig.~\ref{fig:archs}a.7). Executor sets up the environment required by
% each task and then forks each task for execution (Fig.~\ref{fig:archs}a.8).
% This is why tasks are black boxes to RP\@; also note that Scheduler and
% Executor can place and fork heterogeneous tasks, i.e., task requiring
% different type and amount core/GPUs and different execution time.

Fig.~\ref{fig:archs}a's numbers illustrate the resource acquisition and task
execution process. PilotManager uses RS to queue a pilot as a job on the
resource's batch System (Fig.~\ref{fig:archs}a.1-2). Once scheduled, the
pilot bootstraps RP Agent's components, using Updater to notify RP Client
that is ready to execute tasks (Fig.~\ref{fig:archs}a.3). Upon notification,
UnitManager queues all the available tasks onto Client's Scheduler and, after
staging files if required, tasks are queued to the RP Agent's Scheduler
(Fig.~\ref{fig:archs}a.4-6). Scheduler places tasks on suitable partitions of
the pilot's resources and then queues tasks to the Executor so that, when
those partitions of resource becomes available, tasks are executed
(Fig.~\ref{fig:archs}a.7). Executor sets up the environment required by each
task and then forks each task for execution (Fig.~\ref{fig:archs}a.8). 
% This is why tasks are black boxes to RP\@; also note that Scheduler and
% Executor can place and fork heterogeneous tasks, i.e., task requiring
% different type and amount core/GPUs and different execution time.

RP API cannot express dependences among tasks. For RP, every task that is
passed to UnitManager is assumed to be ready for execution. For example,
assume a typical simulation-analysis workflow for molecular dynamics with a
simulation stage and an analysis stage that depends upon the completion of
the simulation stage. Users can explicitly code priorities among stages in
the applications they write with the RP API but they have no dedicated
abstractions in that API for expressing those priorities. EnTK offers these
abstractions at API level: each stage of each pipeline is submitted to RP for
execution, respecting their priority relation.

Fig.~\ref{fig:archs}b's numbers illustrate the execution of workflows in
EnTK\@. Users instantiate an AppManager (Lis.~\ref{code:amgr}), define a set
of resources on which to run their workflow (Lis.~\ref{code:res}), describe
that workflow in terms of pipelines, stages and tasks (Lis.~\ref{code:pst})
and execute it (Lis.~\ref{code:exec}). AppManager passes a copy of the
workflow description to WFProcessor that, based on the priorities between
stages and tasks, uses Enquerer to queue tasks that are ready for execution
to TaskManager (Fig.~\ref{fig:archs}b.1). Meanwhile, ResManager users
the chosen runtime system to acquire the requested resources
(Fig.~\ref{fig:archs}b.2) and, once available, TaskManager uses those
resources to execute the queued tasks (Fig.~\ref{fig:archs}b.3) and dequeuing
them once they have been executed. ExecManager uses queues to communicate the
state of each task execution to AppManager (Fig.~\ref{fig:archs}b.4). Note
that AppManager is the only stateful component of EnTK\@: both WFProcessor
and ExecManager can fail without loss of information about the execution.

